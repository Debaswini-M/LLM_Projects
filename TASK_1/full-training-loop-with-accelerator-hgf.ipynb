{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification, get_scheduler\nfrom torch. utils. data import DataLoader\nfrom accelerate import Accelerator\nfrom torch .optim import AdamW\nfrom tqdm. auto import tqdm\nimport evaluate\n\ndef training_function():\n    \n    #Preprocessing data\n    raw_datasets = load_dataset(\"glue\",\"mrpc\")\n    checkpoint = \"bert-base-uncased\"\n    tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n\n    def tokenize_function(example):\n        return tokenizer(example[\"sentence1\"],example[\"sentence2\"],truncation=True)\n    tokenized_datasets = raw_datasets.map(tokenize_function,batched = True)\n    data_collator = DataCollatorWithPadding(tokenizer = tokenizer)\n    \n    #Model Training \n    tokenized_datasets = tokenized_datasets.remove_columns([\"sentence1\",\"sentence2\",\"idx\"])\n    tokenized_datasets = tokenized_datasets.rename_column(\"label\",\"labels\")\n    tokenized_datasets.set_format(\"torch\")\n    tokenized_datasets[\"train\"].column_names\n    \n    #Defining dataloader\n    train_dataloader = DataLoader(\n        tokenized_datasets[\"train\"],\n        shuffle=True,\n        batch_size=8,\n        collate_fn = data_collator\n    )\n    eval_dataloader = DataLoader(\n        tokenized_datasets[\"validation\"],\n        batch_size=8,\n        collate_fn = data_collator\n    )\n\n    #instantiating model with accelerator\n    accelerator = Accelerator()\n    model = AutoModelForSequenceClassification.from_pretrained(checkpoint,num_labels=2)\n    optimizer = AdamW(model.parameters(),lr=3e-5)\n    train_dl,eval_dl,model,optimizer = accelerator.prepare(\n        train_dataloader,eval_dataloader,model,optimizer\n    )\n    num_epochs=3\n    num_training_steps = num_epochs * len(train_dl)\n    lr_scheduler = get_scheduler(\n        \"linear\",\n        optimizer = optimizer,\n        num_warmup_steps =0,\n        num_training_steps = num_training_steps\n    )\n    \n    #progressbar\n    progress_bar = tqdm(range(num_training_steps))\n    \n    model.train()\n    for epoch in range(num_epochs):\n        for batch in train_dl:\n            outputs = model(**batch)\n            loss= outputs.loss\n            accelerator.backward(loss)\n\n            optimizer.step()\n            lr_scheduler.step()\n            optimizer.zero_grad()\n            progress_bar.update(1)\n    #Model evaluation\n    metric = evaluate.load(\"glue\", \"mrpc\")\n    model.eval()\n\n\n    for batch in eval_dl:\n        with torch.no_grad():\n            outputs = model(**batch)\n\n            logits = outputs.logits\n            predictions = torch.argmax(logits, dim=-1)\n\n            predictions, references = accelerator.gather((predictions, batch[\"labels\"]))\n\n            metric.add_batch(\n            predictions=predictions,\n            references=references)\n    eval_metric = metric.compute()\n\n    accelerator.print(f\"Accuracy: {eval_metric['accuracy']:.4f}, \"f\"F1: {eval_metric['f1']:.4f}\")\n\n    \n   \n\n    \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T08:22:30.585476Z","iopub.execute_input":"2026-01-02T08:22:30.585903Z","iopub.status.idle":"2026-01-02T08:22:30.596045Z","shell.execute_reply.started":"2026-01-02T08:22:30.585875Z","shell.execute_reply":"2026-01-02T08:22:30.595393Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"from accelerate import notebook_launcher\nnotebook_launcher(training_function,num_processes= 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T08:22:33.679935Z","iopub.execute_input":"2026-01-02T08:22:33.680457Z","iopub.status.idle":"2026-01-02T08:25:40.995944Z","shell.execute_reply.started":"2026-01-02T08:22:33.680426Z","shell.execute_reply":"2026-01-02T08:25:40.995189Z"}},"outputs":[{"name":"stdout","text":"Launching training on one GPU.\n","output_type":"stream"},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1377 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52ffa3ae6e0047ebb8197fcb11c34662"}},"metadata":{}},{"name":"stdout","text":"Accuracy: 0.8603, F1: 0.8998\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"!pip install evaluate\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T07:33:29.260191Z","iopub.execute_input":"2026-01-02T07:33:29.260954Z","iopub.status.idle":"2026-01-02T07:33:34.859343Z","shell.execute_reply.started":"2026-01-02T07:33:29.260920Z","shell.execute_reply":"2026-01-02T07:33:34.858389Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.4.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\nRequirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.5)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.18)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.10.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.36.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.20.1)\nRequirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (22.0.0)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (0.28.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.1rc0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.11.12)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.3)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (4.12.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate) (0.16.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nDownloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.6\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}